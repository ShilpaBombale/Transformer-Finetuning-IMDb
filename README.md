# FT-Language-Models-for-Sentiment-Analysis

This project focuses on fine-tuning language models for sentiment analysis on the IMDb review dataset using Hugging Face and parameter-efficient fine-tuning (PEFT) techniques such as LoRA (Low-Rank Adaptation).

### Models Used:
- **DistilBERT_base_uncased**: ~70M parameters
- **Albert_base_v2**: 11.8M parameters

### Tools & Libraries:
- **Hugging Face Transformers**: For model training and inference.
- **PEFT & LoRA**: To enable efficient fine-tuning with reduced computational resources.

### Task:
Fine-tuning the models for sentiment classification on IMDb reviews.

---
